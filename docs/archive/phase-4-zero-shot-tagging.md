# Phase 4a Completion: Adaptive Zero-Shot Tagging (Core)

> **Status:** Complete
> **Milestone:** `photon process image.jpg` outputs semantic tags with confidence scores from a 68K-term WordNet vocabulary

---

## What was built

Phase 4a implements zero-shot image classification using SigLIP's text encoder and a WordNet-derived vocabulary of ~68,000 nouns plus ~260 supplemental visual terms. Each image is scored against the full vocabulary via dot product of pre-computed text embeddings against image embeddings, with SigLIP's learned sigmoid scoring converting raw cosine similarities into calibrated confidence scores.

### Pipeline addition

```
Validate → Decode → EXIF → Hash → Thumbnail → Embed (SigLIP) → Tag (SigLIP) → JSON
                                                                  ↑ NEW
```

Tags are generated by scoring the image embedding against all vocabulary term embeddings in a single matrix-vector dot product (~2ms for 68K terms on CPU).

---

## Sub-phases implemented

### 4a.pre — Vision encoder output fix

**Changed:** `SigLipSession::embed()` in `embedding/siglip.rs`

The Phase 3 implementation extracted `last_hidden_state` (1st output, shape [1, 196, 768]) and mean-pooled it. This works for image-to-image similarity but breaks cross-modal alignment.

**Fix:** Now extracts `pooler_output` by name (2nd output, shape [1, 768]) — the model's intended cross-modal embedding. Mean-pooling code removed entirely.

### 4a.0 — Multi-resolution model download + quality flag

**Config changes:**
- `EmbeddingConfig` gained `image_size: u32` field (224 or 384)
- `EmbeddingConfig::image_size_for_model()` helper
- `TaggingConfig` restructured with `enabled`, `min_confidence` (default 0.0), `max_tags` (default 15), nested `VocabularyConfig`
- `Config` gained `vocabulary_dir()` and `taxonomy_dir()` helpers

**Preprocessing:**
- `preprocess()` now accepts `image_size` parameter (was hardcoded to 224)
- `EmbeddingEngine` stores and passes `image_size`

**CLI (`photon process`):**
- `--quality fast|high` flag selects 224 or 384 vision model
- `--no-tagging` flag disables zero-shot tagging
- Fallback with warning if 384 variant not installed

**Model download (`photon models download`):**
- Downloads text encoder (`text_model.onnx`, fp32, ~421MB) to `~/.photon/models/`
- Downloads tokenizer (`tokenizer.json`, ~2.3MB) to `~/.photon/models/`
- Installs vocabulary files to `~/.photon/vocabulary/`
- `photon models list` shows vision encoders, shared models, and vocabulary status
- Support for two vision variants (224 default, 384 optional)

### 4a.1 — SigLIP text encoder

**New file:** `tagging/text_encoder.rs`

- `SigLipTextEncoder` wraps `Mutex<ort::Session>` + `tokenizers::Tokenizer`
- Loads `text_model.onnx` and `tokenizer.json` from model directory
- `encode_batch(&[String])` tokenizes texts, pads to 64 tokens, runs batch ONNX inference
- Extracts `pooler_output` by name (same as vision encoder fix)
- SigLIP text model takes only `input_ids` — no attention_mask
- All outputs L2-normalized

### 4a.2 — Vocabulary loading

**New file:** `tagging/vocabulary.rs`

Two vocabulary files:
- `wordnet_nouns.txt` — 67,893 nouns from WordNet 3.0, format: `term<TAB>synset_id<TAB>hypernym_chain`
- `supplemental.txt` — 259 scene/mood/style/weather/time/activity/color/composition terms

`Vocabulary` struct loads both files, builds a name→index lookup HashMap, and provides `prompts_for()` for prompt template generation.

### 4a.3 — Label bank (vocabulary embedding cache)

**New file:** `tagging/label_bank.rs`

On first run, all vocabulary terms are encoded through the text encoder using `"a photo of a {term}"` prompts, batched efficiently (64 terms per ONNX call). The resulting N×768 matrix is saved to `~/.photon/taxonomy/label_bank.bin` as raw f32 binary.

Subsequent runs load the cached label bank instantly (~200MB, loads in <1s).

**Performance note:** First-run encoding takes ~90 minutes on CPU (Asahi Linux aarch64). This is a one-time cost. The plan estimated 2-3 minutes on GPU. Phase 4b (progressive encoding) will address this with chunked startup and background encoding.

### 4a.4 — Flat brute-force scoring

**New file:** `tagging/scorer.rs`

`TagScorer::score()` computes dot products of image embedding against all term embeddings, applies SigLIP's sigmoid scoring:

```
logit = 117.33 * cosine_similarity + (-12.93)
confidence = sigmoid(logit)
```

Then sorts by confidence descending and truncates to `max_tags`.

**Confidence calibration note:** SigLIP base model produces very small absolute cosine similarities between image and text embeddings (0.03-0.10 range for matching terms). The sigmoid transformation preserves correct ranking but yields low absolute confidence values. `min_confidence` defaults to 0.0 (disabled), relying on `max_tags` for output limiting. Relative ordering is meaningful; absolute confidence values are not directly interpretable as probabilities.

Scoring completes in ~2ms for 68K terms (pure CPU dot product, no ONNX needed).

### 4a.5 — Pipeline integration

`ImageProcessor` gains:
- `tag_scorer: Option<Arc<TagScorer>>` field
- `load_tagging(&Config)` method (opt-in, same pattern as `load_embedding()`)
- `has_tagging()` method
- Tagging step in `process_with_options()` after embedding, before output

`ProcessOptions` gains `skip_tagging: bool`.

### 4a.6 — Vocabulary data generation

**New file:** `scripts/generate_wordnet_vocab.py`

Python script using NLTK's WordNet to generate `wordnet_nouns.txt`. Uses first lemma per synset, includes full hypernym chains. Generated file (67,893 terms, 6.4MB) shipped in `data/vocabulary/` and installed to `~/.photon/vocabulary/` during `models download`.

Supplemental vocabulary (259 terms) manually curated covering scenes, moods, styles, weather, time of day, activities, colors, and composition types.

---

## Error handling

Added `PipelineError::Model { message }` variant for non-per-image errors (text encoder load failures, tokenizer errors, label bank corruption, lock poisoning). Distinct from `Embedding { path, message }` which is per-image.

---

## Dependencies added

```toml
tokenizers = "0.20"  # SentencePiece tokenizer for SigLIP text encoder
```

---

## Files created/modified

```
Created:
  crates/photon-core/src/tagging/mod.rs          # Module exports
  crates/photon-core/src/tagging/text_encoder.rs  # SigLIP text encoder wrapper
  crates/photon-core/src/tagging/vocabulary.rs    # WordNet vocabulary loader
  crates/photon-core/src/tagging/label_bank.rs    # Pre-computed term embeddings cache
  crates/photon-core/src/tagging/scorer.rs        # Flat brute-force scoring
  data/vocabulary/wordnet_nouns.txt               # 67,893 WordNet nouns (~6.4MB)
  data/vocabulary/supplemental.txt                # 259 curated visual terms
  scripts/generate_wordnet_vocab.py               # WordNet vocabulary generator

Modified:
  crates/photon-core/src/embedding/siglip.rs      # Use pooler_output instead of last_hidden_state
  crates/photon-core/src/embedding/preprocess.rs  # Parameterized image_size
  crates/photon-core/src/embedding/mod.rs         # EmbeddingEngine stores image_size
  crates/photon-core/src/config.rs                # EmbeddingConfig.image_size, TaggingConfig, VocabularyConfig
  crates/photon-core/src/error.rs                 # Added PipelineError::Model variant
  crates/photon-core/src/lib.rs                   # Added tagging module
  crates/photon-core/src/pipeline/processor.rs    # Tag scoring integration
  crates/photon-core/Cargo.toml                   # Added tokenizers dependency
  crates/photon/src/cli/process.rs                # --quality, --no-tagging flags
  crates/photon/src/cli/models.rs                 # Multi-variant download, text encoder, vocabulary install
```

---

## Disk layout

```
~/.photon/models/
├── siglip-base-patch16/         # 224 variant (default)
│   └── visual.onnx              # ~372MB
├── siglip-base-patch16-384/     # 384 variant (optional)
│   └── visual.onnx              # ~350MB
├── text_model.onnx              # Shared text encoder, fp32 (~421MB)
└── tokenizer.json               # Shared tokenizer (~2.3MB)

~/.photon/vocabulary/
├── wordnet_nouns.txt            # 67,893 WordNet nouns
└── supplemental.txt             # 259 curated visual terms

~/.photon/taxonomy/
└── label_bank.bin               # Cached term embeddings (~200MB)
```

---

## Test results

32 tests pass (was 29 before Phase 4):
- New: `test_cosine_to_confidence_range`, `test_sigmoid_monotonic`, `test_preprocess_shape_384`
- All existing Phase 1-3 tests continue to pass

---

## End-to-end results

Example tags produced by `photon process`:

**dog.jpg** — guide dog, sporting dog, hunting dog, retriever, hearing dog, dog breeding, bird dog, Labrador retriever, water dog, police dog, shepherd dog

**beach.jpg** — seascape (0.16), plage (0.08), sea bathing (0.07), seashore (0.05), beach erosion (0.03), coastline (0.02), sea breeze, barrier island, sunset

**car.jpg** — mustang (0.03), shooting brake, pace car, ford, car company, coupe, motoring, automobile race, sports car

Tags are semantically accurate and correctly differentiate images. Beach gets notably higher confidence values (0.16 top) than dog (0.002 top) or car (0.03 top), reflecting different levels of visual-semantic specificity.

Second-run timing (cached label bank): ~3.5s total processing time per image (dominated by ONNX model loading; scoring itself is ~2ms).

---

## Known limitations and future work

1. **First-run encoding is slow on CPU** (~90 min for 68K terms on aarch64). Phase 4b will add progressive encoding (2-3s startup with background encoding).

2. **No hierarchy deduplication** — if both "labrador" and "dog" pass the confidence threshold, both appear in output. Phase 4e will add ancestor suppression using WordNet hypernym chains.

3. **Single prompt template** — uses "a photo of a {term}" for efficiency. Multi-prompt averaging (the plan's original approach) produces slightly better embeddings but at 3× the encoding cost.

4. **No interactive model selection** — `models download` currently auto-downloads the 224 variant. Interactive selection (arrow keys) was deferred to avoid adding a TUI dependency.

5. **Vocabulary is English-only** — WordNet provides English nouns. Multilingual support would require alternative vocabularies.

6. **Low absolute confidence values** — SigLIP base model's sigmoid confidence values are very low (0.001-0.16 for top tags). The LOGIT_SCALE/LOGIT_BIAS were derived from the combined model's binary matching objective, not zero-shot classification against 68K candidates. Relative ordering is correct; absolute values require calibration or normalization for user-facing confidence display.

7. **Some noise tags from WordNet** — Terms like "dog laurel" (a plant), "Calostoma lutescens" (a fungus), and "canine distemper" (a disease) appear alongside legitimate dog tags because they contain "dog" in their WordNet definition/hypernym chain. Phase 4e hierarchy deduplication and 4c relevance pruning will address this.

---

## Phase 4b-4e (deferred optimizations)

These phases are not blocking for Phase 5 and can be implemented later:

| Phase | What | Status |
|-------|------|--------|
| **4b** | Progressive encoding (2-3s startup) | Not started |
| **4c** | Relevance pruning (three-pool system) | Not started |
| **4d** | Neighbor expansion (WordNet siblings) | Not started |
| **4e** | Hierarchy deduplication (ancestor suppression) | Not started |
